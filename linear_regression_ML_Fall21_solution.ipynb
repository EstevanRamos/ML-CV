{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_ML_Fall21_solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE40VgenQhTn"
      },
      "source": [
        "# **CS 4361/5361 Machine Learning**\n",
        "\n",
        "**Linear Regression**\n",
        "\n",
        "**Author:** [Olac Fuentes](http://www.cs.utep.edu/ofuentes/)<br>\n",
        "**Last modified:** 2021/09/30<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKhk4OccQm_2"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,mean_squared_error,mean_absolute_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acybAl3lQtpV"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpwkooQ5QzCO"
      },
      "source": [
        "df = pd.read_csv('gpu_running_time.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaYlFsoqQ4zu"
      },
      "source": [
        "data = df.to_numpy()\n",
        "X = data[:,:14]\n",
        "y = np.mean(data[:,14:],axis=1)\n",
        "feature_names = df.columns\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4361)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMhQ4WxXRCPF"
      },
      "source": [
        "b = np.mean(y_train)\n",
        "W = np.matmul(np.linalg.pinv(X_train),(y_train-np.mean(y_train)).reshape(-1,1))\n",
        "W.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogSMUbVHb_1k"
      },
      "source": [
        "pred = np.matmul(X_test,W) + b\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y_test)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pameMuNWcq9g"
      },
      "source": [
        "Now, using the sklearn implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXpGBJ9kcGdM"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roxmjg5Qcb7r"
      },
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y_test)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3ZeQoPvtB9V"
      },
      "source": [
        "pred = model.predict(X_train)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y_train)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVI9I9_RLHXN"
      },
      "source": [
        "Let's consider a synthetic dataset implementing the function y = 3x + 5, with some noise added."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE6rmPqKLIfX"
      },
      "source": [
        "x = np.random.uniform(low=-5,high=15,size =(200,1))\n",
        "y = 3*x + 5\n",
        "y = y + np.random.normal(scale=5, size =(200,1)) \n",
        "plt.plot(x,y,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daL0TDKtLPuY"
      },
      "source": [
        "Let's see if sklearn can learn the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c64Yy75VLQvi"
      },
      "source": [
        "model = LinearRegression()\n",
        "model.fit(x,y)\n",
        "pred = model.predict(x)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQoZUqd9LYEF"
      },
      "source": [
        "The parameters learned by the model are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdIR2Zu3LZDo"
      },
      "source": [
        "print(model.coef_)\n",
        "print(model.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7srZCLfLcMY"
      },
      "source": [
        "where model.coef_ is the array W and model.intercept_ is the scalar b in our equations above.\n",
        "\n",
        "Now let's plot what the model learned (in orange) compared with the original data (in blue). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JeVy6_hLiRK"
      },
      "source": [
        "plt.plot(x,y,'.')\n",
        "plt.plot(x,pred,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oimugzJ-LvoY"
      },
      "source": [
        "Now let's try to learn a quadartic function.\n",
        "\n",
        "y = 2x^2 - 5x + 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfV-9bXiL_YX"
      },
      "source": [
        "x = np.random.uniform(low=-5,high=15,size =(200,1))\n",
        "y = 2*x**2 - 5*x + 3\n",
        "y = y + np.random.normal(scale=5, size =(200,1)) \n",
        "plt.plot(x,y,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uybnl9RXL3YC"
      },
      "source": [
        "model = LinearRegression()\n",
        "model.fit(x,y)\n",
        "pred = model.predict(x)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y)))\n",
        "\n",
        "print('Model parameters:')\n",
        "print(model.coef_)\n",
        "print(model.intercept_)\n",
        "\n",
        "plt.plot(x,y,'.')\n",
        "plt.plot(x,pred,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udHkhKXpMFdf"
      },
      "source": [
        "Performance is bad using the original features. We can add x^2 as an extra feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4A4LPeMS5L"
      },
      "source": [
        "model = LinearRegression()\n",
        "xx = np.hstack((x,x**2))\n",
        "model.fit(xx,y)\n",
        "pred = model.predict(xx)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y)))\n",
        "\n",
        "print('Model parameters:')\n",
        "\n",
        "print(model.coef_)\n",
        "print(model.intercept_)\n",
        "\n",
        "plt.plot(x,y,'.')\n",
        "plt.plot(x,pred,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvpb7iX7MWN_"
      },
      "source": [
        "Performance is much better.\n",
        "\n",
        "Since in practice we don't know what terms y depends on, we can add the terms that we think MIGHT be useful, hoping the algorithm will figure out which ones are important.\n",
        "\n",
        "Let's include x^2, x^3 and x^4 terms. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpViVZOlMf4H"
      },
      "source": [
        "model = LinearRegression()\n",
        "xx = np.hstack((x,x**2,x**3,x**4))\n",
        "model.fit(xx,y)\n",
        "pred = model.predict(xx)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y)))\n",
        "\n",
        "print('Model parameters:')\n",
        "\n",
        "print(model.coef_)\n",
        "print(model.intercept_)\n",
        "\n",
        "plt.plot(x,y,'.')\n",
        "plt.plot(x,pred,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgmeenoHMFaR"
      },
      "source": [
        "Performance is still good and the algorithm assigns small weights to the irrelevant features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_qIYmagknS"
      },
      "source": [
        "**Exercises:**\n",
        "\n",
        "1.  Add quadratic features to the gpu dataset and evaluate the performance of linear regression\n",
        "2. Use a one-hot representation to classify the MNIST dataset using linear regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svloN7LzgVfy"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4361)\n",
        "for i in range(X.shape[1]):\n",
        "  for j in range(i, X.shape[1]):\n",
        "    X_train = np.hstack((X_train, (X_train[:,i]*X_train[:,j]).reshape(-1,1)))\n",
        "    X_test = np.hstack((X_test, (X_test[:,i]*X_test[:,j]).reshape(-1,1)))\n",
        "  print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNnTiGbkJ2LD"
      },
      "source": [
        "A faster implementation using broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-llNjFEFmYe_"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4361)\n",
        "for i in range(X.shape[1]):\n",
        "  X_train = np.hstack((X_train, (X_train[:,i:i+1]*X_train[:,i:X.shape[1]])))\n",
        "  X_test = np.hstack((X_test, (X_test[:,i:i+1]*X_test[:,i:X.shape[1]])))\n",
        "  print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6NjnmuRAJy8"
      },
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "print('Mean squared error = {:5.2f}'.format(mean_squared_error(pred,y_test)))\n",
        "print('Mean absolute error =  {:5.2f}'.format(mean_absolute_error(pred,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAwiHbCc-uYk"
      },
      "source": [
        "def onehot(y):\n",
        "  y_oh = np.zeros((len(y), np.amax(y)+1), dtype=int)\n",
        "  y_oh[np.arange(len(y)), y]=1\n",
        "  return y_oh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIxM_515-_DE"
      },
      "source": [
        "def onehot_to_class(y_oh):\n",
        "  return np.argmax(y_oh,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpSHnlw3-cGd"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULt4lJOR_PNV"
      },
      "source": [
        "model = LinearRegression()\n",
        "model.fit(x_train,onehot(y_train))\n",
        "pred = onehot_to_class(model.predict(x_test))\n",
        "\n",
        "print('Accuracy = {:7.4f}'.format(accuracy_score(pred,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}